{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "093e007d-a653-4b40-b4b1-2cfc44c2b725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-18 08:29:37--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "wget: /Users/ajithj/.netrc:1: unknown token \"Host\"\n",
      "wget: /Users/ajithj/.netrc:1: unknown token \"gitlab.com\"\n",
      "wget: /Users/ajithj/.netrc:2: warning: ‘login’ token appears before any machine name\n",
      "wget: /Users/ajithj/.netrc:3: warning: ‘password’ token appears before any machine name\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt’\n",
      "\n",
      "input.txt           100%[===================>]   1.06M  5.14MB/s    in 0.2s    \n",
      "\n",
      "2023-01-18 08:29:37 (5.14 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea7c192a-30e5-4f45-9c21-7a22ce4295aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read it in to inspect it\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6f28abf-a3c9-4dc1-89f6-317dc4259d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 1115394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you know Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us kill him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be done: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citizens, the patricians good.\\nWhat authority surfeits on would relieve us: if they\\nwould yield us but the superfluity, while it were\\nwholesome, we might guess they relieved us humanely;\\nbut they think we are too dear: the leanness that\\nafflicts us, the object of our misery, is as an\\ninventory to particularise their abundance; our\\nsufferance is a gain to them Let us revenge this with\\nour pikes, ere we become rakes: for the gods know I\\nspeak this in hunger for bread, not in thirst for revenge.\\n\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Dataset length: {len(text)}')\n",
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b9b7fde-0187-4cd9-9c04-a13809eb78e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "Length of vocab: 65\n"
     ]
    }
   ],
   "source": [
    "# all unique characters in the dataset\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(f'Length of vocab: {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eb2a8ce-d14d-4c19-b988-d3efb6f9be00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 43, 50, 50, 53, 1, 32, 56, 39, 52, 57, 44, 53, 56, 51, 43, 56, 2]\n",
      "Hello Transformer!\n"
     ]
    }
   ],
   "source": [
    "# create a mapping of characters to integers\n",
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "\n",
    "#encoder: take a string and return a list of integers mapped to that string\n",
    "encode = lambda s: [stoi[ch] for ch in s] \n",
    "\n",
    "#decoder: take a list of integers and return a string\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "str = \"Hello Transformer!\"\n",
    "print(encode(str))\n",
    "print(decode(encode(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f668db12-3152-4280-9f90-eb9a85735d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Encode the entire dataset and store it as a tensor in Torch\n",
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8db1ff3-af2e-4f7a-8660-86ab5b479bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data length: 1003854, Valid data length: 111540\n"
     ]
    }
   ],
   "source": [
    "# Train and Validation data sets\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "print(f'Train data length: {len(train_data)}, Valid data length: {len(val_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ad2d4f1-361c-40a2-ba29-9b1f076c5487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8cb263a-0723-4e43-9463-c71822dbf556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input in tensor([18]) (F), target is 47 (i)\n",
      "when input in tensor([18, 47]) (Fi), target is 56 (r)\n",
      "when input in tensor([18, 47, 56]) (Fir), target is 57 (s)\n",
      "when input in tensor([18, 47, 56, 57]) (Firs), target is 58 (t)\n",
      "when input in tensor([18, 47, 56, 57, 58]) (First), target is 1 ( )\n",
      "when input in tensor([18, 47, 56, 57, 58,  1]) (First ), target is 15 (C)\n",
      "when input in tensor([18, 47, 56, 57, 58,  1, 15]) (First C), target is 47 (i)\n",
      "when input in tensor([18, 47, 56, 57, 58,  1, 15, 47]) (First Ci), target is 58 (t)\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f'when input in {context} ({decode(context.tolist())}), target is {target} ({decode([target.tolist()])})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d8c8f1d-76ae-46ad-abfd-971e2efcc2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: torch.Size([8, 8]), targets: torch.Size([8, 8])\n",
      "xb =  tensor([[53, 59,  6,  1, 58, 56, 47, 40],\n",
      "        [49, 43, 43, 54,  1, 47, 58,  1],\n",
      "        [13, 52, 45, 43, 50, 53,  8,  0],\n",
      "        [ 1, 39,  1, 46, 53, 59, 57, 43],\n",
      "        [57,  0, 58, 46, 39, 52,  1, 50],\n",
      "        [26, 19,  1, 20, 17, 26, 30, 37],\n",
      "        [43,  8,  0,  0, 31, 43, 41, 53],\n",
      "        [54, 54, 63,  1, 40, 56, 43, 43]])\n",
      "yb =  tensor([[59,  6,  1, 58, 56, 47, 40, 59],\n",
      "        [43, 43, 54,  1, 47, 58,  1, 58],\n",
      "        [52, 45, 43, 50, 53,  8,  0, 26],\n",
      "        [39,  1, 46, 53, 59, 57, 43,  0],\n",
      "        [ 0, 58, 46, 39, 52,  1, 50, 43],\n",
      "        [19,  1, 20, 17, 26, 30, 37,  1],\n",
      "        [ 8,  0,  0, 31, 43, 41, 53, 52],\n",
      "        [54, 63,  1, 40, 56, 43, 43, 42]])\n",
      "------\n",
      "when input in tensor([53]) (o), target is 59 (u)\n",
      "when input in tensor([53, 59]) (ou), target is 6 (,)\n",
      "when input in tensor([53, 59,  6]) (ou,), target is 1 ( )\n",
      "when input in tensor([53, 59,  6,  1]) (ou, ), target is 58 (t)\n",
      "when input in tensor([53, 59,  6,  1, 58]) (ou, t), target is 56 (r)\n",
      "when input in tensor([53, 59,  6,  1, 58, 56]) (ou, tr), target is 47 (i)\n",
      "when input in tensor([53, 59,  6,  1, 58, 56, 47]) (ou, tri), target is 40 (b)\n",
      "when input in tensor([53, 59,  6,  1, 58, 56, 47, 40]) (ou, trib), target is 59 (u)\n",
      "when input in tensor([49]) (k), target is 43 (e)\n",
      "when input in tensor([49, 43]) (ke), target is 43 (e)\n",
      "when input in tensor([49, 43, 43]) (kee), target is 54 (p)\n",
      "when input in tensor([49, 43, 43, 54]) (keep), target is 1 ( )\n",
      "when input in tensor([49, 43, 43, 54,  1]) (keep ), target is 47 (i)\n",
      "when input in tensor([49, 43, 43, 54,  1, 47]) (keep i), target is 58 (t)\n",
      "when input in tensor([49, 43, 43, 54,  1, 47, 58]) (keep it), target is 1 ( )\n",
      "when input in tensor([49, 43, 43, 54,  1, 47, 58,  1]) (keep it ), target is 58 (t)\n",
      "when input in tensor([13]) (A), target is 52 (n)\n",
      "when input in tensor([13, 52]) (An), target is 45 (g)\n",
      "when input in tensor([13, 52, 45]) (Ang), target is 43 (e)\n",
      "when input in tensor([13, 52, 45, 43]) (Ange), target is 50 (l)\n",
      "when input in tensor([13, 52, 45, 43, 50]) (Angel), target is 53 (o)\n",
      "when input in tensor([13, 52, 45, 43, 50, 53]) (Angelo), target is 8 (.)\n",
      "when input in tensor([13, 52, 45, 43, 50, 53,  8]) (Angelo.), target is 0 (\n",
      ")\n",
      "when input in tensor([13, 52, 45, 43, 50, 53,  8,  0]) (Angelo.\n",
      "), target is 26 (N)\n",
      "when input in tensor([1]) ( ), target is 39 (a)\n",
      "when input in tensor([ 1, 39]) ( a), target is 1 ( )\n",
      "when input in tensor([ 1, 39,  1]) ( a ), target is 46 (h)\n",
      "when input in tensor([ 1, 39,  1, 46]) ( a h), target is 53 (o)\n",
      "when input in tensor([ 1, 39,  1, 46, 53]) ( a ho), target is 59 (u)\n",
      "when input in tensor([ 1, 39,  1, 46, 53, 59]) ( a hou), target is 57 (s)\n",
      "when input in tensor([ 1, 39,  1, 46, 53, 59, 57]) ( a hous), target is 43 (e)\n",
      "when input in tensor([ 1, 39,  1, 46, 53, 59, 57, 43]) ( a house), target is 0 (\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # whhat is the maximum content length for prediction?\n",
    "\n",
    "def get_batch(split):\n",
    "    #generate a random batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    # create a block_size worth of random indexes within the data - blocksize length\n",
    "    ix = torch.randint(len(data) - block_size - 1, (block_size,))\n",
    "    xb = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    yb = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return xb,yb\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print(f'inputs: {xb.shape}, targets: {yb.shape}')\n",
    "print('xb = ', xb)\n",
    "print('yb = ', yb)\n",
    "print('------')\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f'when input in {context} ({decode(context.tolist())}), target is {target} ({decode([target.tolist()])})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "300478b9-509c-49cb-b4c6-137523417a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[53, 59,  6,  1, 58, 56, 47, 40],\n",
      "        [49, 43, 43, 54,  1, 47, 58,  1],\n",
      "        [13, 52, 45, 43, 50, 53,  8,  0],\n",
      "        [ 1, 39,  1, 46, 53, 59, 57, 43],\n",
      "        [57,  0, 58, 46, 39, 52,  1, 50],\n",
      "        [26, 19,  1, 20, 17, 26, 30, 37],\n",
      "        [43,  8,  0,  0, 31, 43, 41, 53],\n",
      "        [54, 54, 63,  1, 40, 56, 43, 43]])\n"
     ]
    }
   ],
   "source": [
    "# Input to the transformer\n",
    "print(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "394e5a59-39e3-41f1-ad3f-ebab596d95eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a Bigram LM using Torch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        # ifx and targets are both (B, T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) #(B, T, C)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens=100):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get predictions\n",
    "            logits, loss = self(idx)\n",
    "            \n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # shape is now (B, C)\n",
    "            \n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            \n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            \n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58c85a6c-12a3-4be4-9a0d-7fb3984d7742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 65])\n",
      "Loss = 4.823126792907715 - based on vocab_size 65, expected loss is $ln(1/vocab_size)$ -4.174387454986572\n",
      "Generated Text:\n",
      "\n",
      "\n",
      "SKIcLT;AcELMoTbvZv C?nq-QE33:CJqkOKH-q;:la!oiywkHjgChzbQ?u!3bLIgwevmyFJGUGp\n",
      "wnYWmnxKWWev-tDqXErVKLgJ\n"
     ]
    }
   ],
   "source": [
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(f'Loss = {loss} - based on vocab_size {vocab_size}, expected loss is $ln(1/vocab_size)$ {torch.log(torch.tensor(1/vocab_size))}')\n",
    "\n",
    "print('Generated Text:\\n')\n",
    "print(decode(m.generate(idx = torch.zeros((1,1), dtype=torch.long))[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04ca46f2-d555-4bd6-a327-b3648bc165be",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8e7c6fa-4f2d-43f4-b0dc-fa4e384ab4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.750803470611572\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "    \n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "print(loss.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ea686e8-9212-4085-823c-26bfc3a50180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "phhZHotYUhricLIWkza;Z!zPyhsr.DGjsBzP!js$ztSP,cgChixj;;oAmJgCSP!ZJNulD,qbPbj\n",
      "YY!BfzRjNYpWnN&vmR\n",
      "xav:vr'aoTXeZ!Py$kzbkbOfSYszu3XD. -GSt3fREiBegCbjQb&ZKuMgCg\n",
      "-\n",
      "RlnETEluFkzP,nEr&upJ?,;wUy;aSYdeNXoT;,lgnMphiBfyyagwN!z,nsrgLzeD&Gw3SOTWhYUgGMkttdY3rhZARjHoS,iI'dPkzRySV$-w!zRoRLWW:CF$gF$Nzrdo,j?'mcr'Pl&GSbScfZbj?aUYWDYw'&Q-WKpE?hV-QOdq$E?LtcPTHoxc3flzd?SP CBk$z:3b$RKH;Nv'dgf ERIVT;AXe?UuCuaPl:Ck$Eq-A iyhSP pyNmyZXaS..SxcEE!PlvmuQTeEDq-!uLUzo'a-Pn!!$zVjF$gHEr fFVXIB-Q?olyjR'ab?!uBMKR,lS'g:CuDW:t;.iADusru\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6ed22b-9057-4b38-9b90-634adcc5470a",
   "metadata": {},
   "source": [
    "## Understanding self-attention and its mathematical underpinnings\n",
    "\n",
    "Self-attention layers in the decoder allow each position in the decoder to attend to\n",
    "all positions in the decoder up to and including that position. We need to prevent leftward\n",
    "information flow (i.e. from the future) in the decoder to preserve the auto-regressive property. We implement this\n",
    "inside of scaled dot-product attention by masking out (setting to −∞) all values in the input\n",
    "of the softmax which correspond to illegal connections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a81576c6-5331-477d-bd5a-90f6e0a9652f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "a = torch.tril(torch.ones(5,5))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c86e3a51-4149-4ad3-84d3-09aeeb3efcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f39e8b59-451f-4473-b9ae-de9e3ecc2784",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randint(0,10,(5,2)).float()\n",
    "c = a @ b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91854eab-1354-426a-bf09-6105979bceb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]])\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.],\n",
      "        [0., 4.],\n",
      "        [0., 3.]])\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333],\n",
      "        [3.5000, 5.0000],\n",
      "        [2.8000, 4.6000]])\n"
     ]
    }
   ],
   "source": [
    "print(f'a=\\n{a}\\nb=\\n{b}\\nc=\\n{c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "020977c1-2c27-4ca1-b003-0433cc0e1f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consider the following toy example:\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4eea0cba-1389-47f3-bd7e-f2c46be6cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] # (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa7a8712-20dc-4d2f-af7b-5617b0fa9f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2: using matrix multiply for a weighted aggregation\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8f1f4ea-1751-4cab-93d2-c4db3231071b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3: use Softmax\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08173566-59b9-406e-99f6-5104d67926c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version 4: self-attention!\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "B,T,C = 4,8,32 # Batch, Time, and Channels\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# let's build a single head self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k = key(x) # B, T, 16 (head-size)\n",
    "q = query(x) # (B, T, 16)\n",
    "wei = q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) --> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "out.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5847c9ae-6a0f-4c1f-90f9-17ce919a02c1",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "\n",
    "- Attention is a communication mechanism. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
    "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
    "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
    "- In an \"encoder\" attention block just delete the single line that does masking with tril, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
    "- \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
    "- \"Scaled\" attention additional divides wei by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46c025c7-62c7-4749-9998-1c7294d3e82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0449), tensor(1.0700), tensor(17.4690))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = torch.randn(B, T, head_size)\n",
    "q = torch.randn(B, T, head_size)\n",
    "wei = q @ k.transpose(-2, -1)\n",
    "k.var(), q.var(), wei.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d7c2e88-bec3-4d4e-88e6-ed1d34bbcbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9006), tensor(1.0037), tensor(0.9957))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = torch.randn(B, T, head_size)\n",
    "q = torch.randn(B, T, head_size)\n",
    "wei = q @ k.transpose(-2, -1) * head_size ** -0.5\n",
    "k.var(), q.var(), wei.var()\n",
    "# See how the variance is preserved in the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40579d46-c69b-47ba-b64f-67d755b36117",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm1d:\n",
    "    \n",
    "    def __init__(self, dim, eps=1e-5):\n",
    "        self.eps = eps\n",
    "        self.beta = torch.zeros(dim)\n",
    "        self.gamma = torch.ones(dim)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # forward pass\n",
    "        xmean = x.mean(1, keepdim=True) # batch mean\n",
    "        xvar = x.var(1, keepdim=True) # batch variance\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        return self.out\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66099404-8865-46ee-9708-44c96589f990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "module = LayerNorm1d(100)\n",
    "x = torch.randn(32, 100) # batch size 32 of 100-dimensional vectors\n",
    "x = module(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42d32ec5-87be-4c19-b3d4-60ebfbc304e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1469), tensor(0.8803))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0].mean(), x[:,0].std() # mean,std of one feature across all batch inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be014b1d-c368-4000-9e3b-ebf4568f10ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-9.5367e-09), tensor(1.0000))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:].mean(), x[0,:].std() # mean,std of a single input from the batch, of its features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ea3fec-856e-4da9-acf3-3ac7ac40a50a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
